server:
  http_port: 8080
  grpc_port: 9090
  host: "0.0.0.0"
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "60s"

database:
  type: "postgres"
  host: "localhost"
  port: 5432
  name: "advanced_research"
  user: "postgres"
  password: "password"
  ssl_mode: "disable"
  max_connections: 25
  max_idle_connections: 5
  connection_max_lifetime: "5m"

redis:
  host: "localhost"
  port: 6379
  password: ""
  db: 0
  pool_size: 10

integrations:
  lrs:
    enabled: true
    endpoint: "http://localhost:8080/xapi/"
    username: "researcher"
    password: "password"
    timeout: "30s"
    retry_attempts: 3
    batch_size: 10
    
  opencode:
    enabled: true
    api_key: "your-opencode-api-key"
    workspace: "advanced-research"
    git_repo: "https://github.com/advanced-research/docs"
    timeout: "30s"
    
  neuralblitz:
    enabled: true
    backend: "cuda"  # cuda, cpu, mps
    device_id: 0
    memory_fraction: 0.8
    tensor_ops_threads: 4
    max_batch_size: 32
    
logging:
  level: "info"
  format: "json"
  output: "stdout"
  file_output: "/var/log/advanced-research/app.log"
  max_file_size: "100MB"
  max_files: 10
  compress: true

monitoring:
  metrics_enabled: true
  metrics_port: 9091
  tracing_enabled: true
  tracing_endpoint: "http://localhost:14268/api/traces"
  health_check_interval: "30s"

security:
  jwt_secret: "your-jwt-secret-key"
  token_expiry: "24h"
  refresh_token_expiry: "168h"
  bcrypt_cost: 12
  rate_limit:
    enabled: true
    requests_per_minute: 100
    burst_size: 20

processing:
  max_concurrent_queries: 10
  query_timeout: "60s"
  pipeline_timeout: "30m"
  context_max_size: 10000
  context_cleanup_interval: "1h"

cache:
  type: "redis"
  ttl: "1h"
  max_size: 1000
  cleanup_interval: "30m"

features:
  experimental_features: false
  debug_mode: false
  profiling_enabled: false
  auto_save_context: true
  analytics_tracking: true